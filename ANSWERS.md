# Some Responses to the Discussion Questions

1. This max outbound (8) limit was added to bitcoind in 2010. While I couldn't find any statistical proofs, it has been generally accepted by Core devs that increasing the limit will introduce some negative side-effects: (a) increased node outgoing bandwith utilization relaying txns, (b) increased node resource usage since each will likely receive identical inv(data) from many more peers, (c) increased network spike when new blocks are released, (d) potentially decreases decentralization as nodes with little processing power get overwhelmed by larger nodes sending data too fast, (e) there are many more non-listening nodes (behind nat) than listening nodes. so inbound connections to listening nodes are scarce. With all these drawbacks, it seems no one is interested in increasing the limit unless you can prove that it will have a net positive impact on txn/block propagation and health of the overall network. The default max inbound (125 - max_outbound) limit is simpler to explain: (a) consumer routers can have issues with too many TCP connections, (b) you can run out of file descriptors on some OS's, (c) higher memory per connection (send/receive buffers + other data). Note: the inbound limit is configurable for larger nodes via `-maxconnections=125` so you can opt-in to higher resource usage. Links: [1](https://github.com/bitcoin/bitcoin/commit/94cfec07fd302c9ff9b6a80c47418d4fe56596ae), [2](https://github.com/bitcoin/bitcoin/pull/6014#issuecomment-93185470), [3](https://github.com/bitcoin/bitcoin/issues/9217#issuecomment-262825152), [4](https://github.com/bitcoin/bitcoin/pull/4687#discussion_r17206235).
2. Not a “Why” answer, more like “How”: New buckets represent potential new peers that we have not yet established contact with. New allows duplicates (each address could show up in up to 4 new buckets) because it treats the same IP coming from different sources differently. Tried buckets represent peers that we have established meaningful contact. Tried table does not allow duplicates, the same IP always hashes to one single bucket, regardless of where that IP came from. Addresses from new could move to tried or be removed completely if its bucket is full. And interestingly, addresses from tried could also move back to new (evicted). This does not completely answer why we have this two-tier table design in the first place, except for perhaps the aforementioned difference in allowing duplicates. See some code [here](https://github.com/bitcoin/bitcoin/pull/787).
3. Much of the logic is in `net_processing.cpp`. There's a global counter `g_outbound_peers_with_protect_from_disconnect` that increments up to 4. If I read the code correctly, the "protected peers" are automatically added when we process the headers message and see that the peer's best known block is greater than or equal to our current chain tip (this seems to be true even for Initial Block Download - which is a bit strange, given that we still have not yet seen all the headers / the whole chain..). There doesn't seem to be a way for the protected peers to be removed. Not sure if `CNodeState` is serialized to disk / persistent across power cycles or not? If it isn't, then node restart would reset the set of protected peers to empty. See some code [here](https://github.com/bitcoin/bitcoin/blob/master/src/net_processing.cpp#L1755).
4. Diffusion: Instead of using fixed intervals to broadcast and relay INV messages, node now uses a random delay timer. So it picks a neighbor at random AND use a random delay timer per peer, until the tx has been broadcasted / relayed to all reachable peers. Diffusion is still ineffective against deanonymization because despite the random timers, the spreading pattern is still structured/symmetric which betrays the originating source (with good probability). See code [here](https://github.com/bitcoin/bitcoin/commit/5400ef6bcb9d243b2b21697775aa6491115420f3).
5. Original idea was that routes are chosen randomly I think (the way it is implemented in Grin) but BIP156 suggests to assign a specific outbound peer for each inbound peer instead. If the dandelion tx is never turned into a normal tx our node would recognize this as the tx is never coming back to it as such. Then it give it another try by sending the dandelion tx again.
6. 10% is what is suggested in BIP156, certainly a node could override that and that may even be ok. It is possible that there are nodes in the network that just fluff prematurely but the privacy gain is still positive.
7. It does not relayed to random peers in the stem phase but chooses up to two constant peers to forward to, which are changed after an epoch. Own txs are sent out to these same nodes. Diffusion is decided based on node id and epoch, so within one epoch the node diffuses all messages or relay all.
8. See [ariard's gist](https://gist.github.com/ariard/1034cd7624805d53334e80d4712fb8ee).
